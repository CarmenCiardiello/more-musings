[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "My name is Carmen Ciardiello. I am an engineer who has worked in a MLB front office as a Research & Development Analyst and have written at FanGraphs as a part-time contributor. You can easily look back at my FanGraphs archive by searching for my name followed by FanGraphs. Some of my early research can be found at sabermetricmusings.blogspot.com, which can be accessed by clicking on the archive icon.\nFeel free to contact me on Twitter or email me at cciardiello1@gmail.com with any questions or concerns regarding my work on this site or anything else that may cross your mind. I am always happy to discuss baseball, hockey, programming, and all combinations thereof."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sporting Musings",
    "section": "",
    "text": "Robert Stephenson’s Cutter\n\n\n\n\n\n\n\nbaseball\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nJan 21, 2024\n\n\nCarmen Ciardiello\n\n\n\n\n\n\n  \n\n\n\n\nDeveloping a Predictive wOBA Measure\n\n\n\n\n\n\n\nbaseball\n\n\nanalysis\n\n\nmodeling\n\n\n\n\n\n\n\n\n\n\n\nJan 3, 2024\n\n\nCarmen Ciardiello\n\n\n\n\n\n\n  \n\n\n\n\nHockey Microstats Repeatability\n\n\n\n\n\n\n\nhockey\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2024\n\n\nCarmen Ciardiello\n\n\n\n\n\n\n  \n\n\n\n\nHitter Velocity Splits\n\n\n\n\n\n\n\nbaseball\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2024\n\n\nCarmen Ciardiello\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/velocity-splits/index.html",
    "href": "posts/velocity-splits/index.html",
    "title": "Hitter Velocity Splits",
    "section": "",
    "text": "One avenue of analysis I see most around the postseason when individual batter-pitcher matchups or team matchups are more heavily scrutinized is bucketing offensive performance by velocity faced, specifically against fastballs. An analyst might posit “This bullpen has thrown X percent of its fastballs over 95 mph and this team has produced a Y wOBA on such pitches.” Or something along the lines of “John Doe is going to have a tough go of it against this teams cadre of high octane arms; he has posted an X wOBA on fastballs over 95 mph, versus Y on fastballs below that threshold.” Similar points might be made in an analysis of a player in the midst of a slump during the championship season (instances that come to mind are various pieces related to Jose Abreu from 2023, for example). In all of these cases, the performance against what many would call “premium velocity” or “95+”, which at this point in time I would argue does not constitute premium velocity (reminds me of this Effectively Wild episode), is certainly descriptive. We take what happened in the past, create a cutoff (albeit an arbitrary one), and calculate the respective wOBAs.\nThat is all well and good, a description of that happened in the past. But I have few points of contention with type of analysis, either at the player or team level. The first, which I have already alluded to, is the arbitrary point at which most decide to bucket the data. This is almost always 95 mph. I am not aware of why this became the accepted line of demarcation; I would guess it just looks like a nice round number. Or maybe it is related to MLB’s definition of a hard hit ball, also 95 mph. Nevertheless, I can appreciate the desire to bucket information for ease of analysis or understanding. Modelling this in a continuous manner and presenting the results is often a more cumbersome endeavor and may lose some of the readers. A trivial comparison of performance on either side of a cutoff is more digestible. I suggest in the future, maybe we use cutoff based on velocity percentile? League-wide velocity is not a static figure, thus the significance of the 95 mph figure is different in say 2023 versus 2015.\nThe arbitrary buckets are one issue, but like I said I can understand the impetus for wanting to structure analysis in this way. My main issue the the usefulness of this information altogether, in that I am very skeptical that this sort of analysis yields valuable insights into performance in the past or future. The usage of wOBA as the measure of choice belies a player/team’s performance against higher velocity pitches because it only considers pitches that mark the end of a plate appearance. All of the fastballs that a player swings through with either zero or one strike are not considered at all. Furthermore, using wOBA muddies the picture by not distinguishing whether a player/team struggles with making contact or producing damage on contact. If you want to demonstrate an effectiveness (or lack thereof) against velocity, these two skills need to be separated out. The easiest method would be to consider whiff or swinging strike rate and wOBACON (or some measure concerned solely with contact quality). This criticism does not apply to all analyses of this type, but it is something that I see quite often and think needs to be adjudicated. I understand this distinction can be a bit tricky. It requires a few different Savant searches and some spreadsheet jockeying. But failing to make this distinction prohibits any conclusions one draws from being revealing.\nNow, let us move on to the functionality of bucketing performance by velocity faced, even after making the distinction between contact and contact quality. Looking at contact (in the form of swinging strike rate) or contact quality (in the form of wOBACON) there has been been a standard bell curve for deviations in performance against higher and lower velocity, looking solely at players who accumulated 100 plate appearances in a given season since 2015.\n\n\n\n\n\nThere are a few conclusions we can draw from these figures. First, these look like standard Gaussian distributions. The swinging strike rate figure is centered close to around 0.05 (i.e. the median player has a swinging strike rate about five percentage points higher against 95+ mph fastballs). The wOBACON plot is similarly shaped, but around 0 (i.e. the point where there is no difference between a player’s wOBACON when you bucket balls in play by velocity faced). The shapes of both figures indicates one of two things: either the talent in facing higher end velocity (relative to lower velocity) is normally distributed in MLB or the differences in the two figures are random around the league-wide mean. The fact that the wOBACON figure is centered around zero lends credence to the latter; intuitively players should not be expected to produce better against higher velocity. Therefore, using a threshold of 100 PAs, looking at a season’s worth of PAs is not sufficient in judging a player’s ability to face high end velocity. For swinging strikes, there is a bit more to consider given the center of the distribution is located at a value that makes sense; we expect (and know) that higher velocity pitches (all else being equal) result in more whiffs. But still, within a season, any difference that deviates from that medium is mostly noise because year over year, there is little to no consistency in those deviations\n\n\n\n\n\nThis whole post is a long-winded plea to caution analysts looking to find signal in any velocity-based splits when it comes to batting performance (this can undoubtedly be said for any analysis leveraging splits). We know facing higher end velocity is going to result in lower offensive performance on the whole(evident in the depressed offensive environment of the postseason). But there is little to no evidence that players are particularly adept or poor at facing high end velocity relative to lower velocity at the major league level. There might be something to explore when looking at minor league players, where the distribution of talent is much wider. Without extensive minor league pitch-tracking publicly available, however, this is not possible to verify at this point in time."
  },
  {
    "objectID": "posts/microstats-repeatability/index.html",
    "href": "posts/microstats-repeatability/index.html",
    "title": "Hockey Microstats Repeatability",
    "section": "",
    "text": "The proliferation of “microstats” in the public space has been a boon in our understanding of hockey players. These stats include entries/exits (the concept and tracking of which were pioneered by Eric Tulsky), entry denials, and various types of passing plays (which to my knowledge were first studied in depth by Ryan Stimson). Corey Sznajder has been tracking this phylum of statistics and releasing them to the patrons of his All Three Zones project for public consumption and analysis. Corey has been an invaluable in increasing our understanding of the various skills players display while on the ice and his data is readily available for public-facing analysts to dig into.\nThese statistics can tell us why or how a player comes about his production. But they do not approximate player value on their own. Jack Fraser, in a newsletter post from several years ago, cautions people in using microstats to assess player ability. He stresses that these measures events, what actually is happening on the ice. We know that at the team level certain passing plays and transition into and out of the neutral zone are indicators of successfully driving goal differential and generation from the work of Tulsky and Stimson. At the player level this is not necessarily true. There are plenty of players who are not tasked with transporting the puck up the ice that provide significant value to their clubs. Look no further than Jason Robertson. A player not necessarily the most fleet of foot, Robertson defers these responsibilities to his more dynamic linemates (most notably Roope Hintz) and does his part by making himself available to receive passes in the offensive zone, where he can then put shots on net or parley the reception into another pass in the offensive zone to scramble the opposition. I think any fan or analyst following the NHL the past few years would agree that Robertson is one of the better wingers in the league, but he certainly does not stand out when looking at Corey’s tracking of transition plays. At the other end of the spectrum, successfully generating exits and entries is not a one way ticket for effectiveness. Look no further than Max Domi.\nAll of this is to say is that these tracked statistics are not the be all and end all in evaluating hockey players. There are skills that are clearly not captured that help players drive goal differentials for their team. I will say that if a player stands out in all or most of the tracking statistics, there is a decent chance that player is doing something right; but not definitively.\nThat is my preamble and at some point I would like to look deeper into the relationships between microstats and player impact. I have some projects in the works that will hopefully help bridge this gap, such as leveraging the play-by-play tracking data Corey provides to see its effects on expected goal generation, but that is for another time (hopefully). For now, one item that interests me is the consistency of these stats year over year for players that change teams. I alluded to the fact that these measures are dependent on a player’s role to some extent. A player like Connor McDavid would likely find himself carrying the puck a ton no matter the team he played for, but that is an extreme case. Most players would be heavily influenced by their team context and correspondingly would see shifts in their microstats output should they change teams. At least that is my hypothesis. Luckily this can be tested. I know some work has been done by Charlie O’Connor and Garik16 looking at the intra-season stability of entry and exit proclivity. I am not aware, however, of analysis that has been at players looking at inter-season consistency, let alone players that change teams. So that is what I am going to do here.\nBefore a start, I should note a few caveats. Corey does not track every minute of every shift that a player has at 5v5. He is one person, that would be impossible. This will be have to be a source of noise that we will accept when looking at the results. I am choosing to use a 100 minute cutoff for each seasonal pair (i.e. the player has at least 100 minutes tracked at 5v5 in each season). The other main caveat is that I am not taking into account the effects associated with aging. I would imagine, like any other statistics imaginable, that microstats are subject to aging curves. For those curious, I will include some aging curves at the end for the metrics I believe are most consistent across seasons. Finally, I am only using data from the 2017 through the 2020 season because Corey has each of the metrics summarized in a nicely organized spreadsheet. I wanted to get this analysis out there so I did not feel like spending the time it would require to go through the raw play-by-play logs creating the requisite summaries for the 2021 through 2023 seasons. If any of Corey’s patreons (or Corey himself) are aware of a spreadsheet with all of the statistics summarized for the other seasons, let me know and I can rerun my code including the more recent data.\nNow let us look at the results. Based on the criteria I set, there are 1632 eligible player-season pairs. Of those 1632 pairs, 1262 are of players who played on the same team year over year (and thus, 370 who changed clubs). 1062 players in the set are classified as forwards and the remaining 570 are defensemen. The following represents the year over year correlations between various statistics tracked by Corey, split up by whether the player in question changed teams year over year.\n\n\n\n\n\n\n\n\nFirst up are the forwards, with the chart on the left representing forwards who changed teams in between seasons and the chart on the right representing players who were on the same team season over season. Players who stayed put, unsurprisingly, have the higher year over year correlations across the board. These stats (and really all measures of player actions/performance) are some mixture of player skill and context/role. Naturally we want to tease out and isolate player skill, but these measures are undoubtedly influenced by a player’s teammates and the role which his coach asks him to take on.\nThe stats related to transition (exits/entries) are most stable year over year as are the more general measures for passing plays and shot attempts tracked. As the specificity of the offensive play type increases, the correlations decrease given we are dealing with a smaller sample relative to the total sample for shots and passes. The stats tracked covering actions in the defensive zone are basically noise for forwards; these actions are extremely infrequent.\n\n\n\n\n\n\n\n\nThese charts for defenders are oriented in the same way as their forward counterparts; players who changed teams on the left, the rest on the right. Similar to the forwards, the transition stats are stickier; more specifically, the transition stats related to exits. Defenders are much more involved in moving the puck out of their own zone relative to their responsibility for gaining entry into the offensive zone. This will naturally lead to a stronger year over year relationship given this is a responsibility that is more uniformly shared across team contexts whereas the role defenders play in their team’s offensive attack is more variable depending on team structure and coaching. Defenders show much smaller correlations for offensive play-types. As alluded to above, they are less involved offensively and thus we are looking at a smaller sample of plays across seasons. This is also most likely the result of defenders having less control over offensive play than forwards.\nFor the analysis on the whole, it is worth pointing out that we are looking at correlations (\\(R\\)), not coefficients of determination (\\(R^{2}\\)). The latter represents the proportion of one measure that can explain the other’s (in this case seasons N and N+1) variance. Thus, a correlation of approximately 0.707 (\\(\\frac{1}{\\sqrt{2}}\\)) would mean that the prior season’s values explain half the variance in the current season. Take a gander at the prior two charts. Very few measures for both player types reach that 50% threshold. Correlations of about 0.316 would indicate just a 10% \\(R^{2}\\). Arbitrary endpoints and whatnot, but no matter how we slice it there’s very little signal year over year signal, especially for players who change teams. We can conclude that much of these microstats are more descriptive than prescriptive and we should be paying most attention to entries/exits at a high level, shot and passing generation on the whole (i.e. without segmenting by type). That is not to tracking these play types and entry defense is not important in our understanding of the game; there is plenty of research that shows these are essential to goal generation and prevention. Moreover, for individual players, it seems that many of them do not represent repeatable skill across seasons and are highly dependent on team context and good old-fashioned variance.\nFinally, I will leave you with some aging curves for the more stable metrics. If there are any metrics not included here, feel free to contact me and I can produce those on your behalf."
  },
  {
    "objectID": "posts/microstats-repeatability/index.html#overview",
    "href": "posts/microstats-repeatability/index.html#overview",
    "title": "Hockey Microstats Repeatability",
    "section": "",
    "text": "The proliferation of “microstats” in the public space has been a boon in our understanding of hockey players. These stats include entries/exits (the concept and tracking of which were pioneered by Eric Tulsky), entry denials, and various types of passing plays (which to my knowledge were first studied in depth by Ryan Stimson). Corey Sznajder has been tracking this phylum of statistics and releasing them to the patrons of his All Three Zones project for public consumption and analysis. Corey has been an invaluable in increasing our understanding of the various skills players display while on the ice and his data is readily available for public-facing analysts to dig into.\nThese statistics can tell us why or how a player comes about his production. But they do not approximate player value on their own. Jack Fraser, in a newsletter post from several years ago, cautions people in using microstats to assess player ability. He stresses that these measures events, what actually is happening on the ice. We know that at the team level certain passing plays and transition into and out of the neutral zone are indicators of successfully driving goal differential and generation from the work of Tulsky and Stimson. At the player level this is not necessarily true. There are plenty of players who are not tasked with transporting the puck up the ice that provide significant value to their clubs. Look no further than Jason Robertson. A player not necessarily the most fleet of foot, Robertson defers these responsibilities to his more dynamic linemates (most notably Roope Hintz) and does his part by making himself available to receive passes in the offensive zone, where he can then put shots on net or parley the reception into another pass in the offensive zone to scramble the opposition. I think any fan or analyst following the NHL the past few years would agree that Robertson is one of the better wingers in the league, but he certainly does not stand out when looking at Corey’s tracking of transition plays. At the other end of the spectrum, successfully generating exits and entries is not a one way ticket for effectiveness. Look no further than Max Domi.\nAll of this is to say is that these tracked statistics are not the be all and end all in evaluating hockey players. There are skills that are clearly not captured that help players drive goal differentials for their team. I will say that if a player stands out in all or most of the tracking statistics, there is a decent chance that player is doing something right; but not definitively.\nThat is my preamble and at some point I would like to look deeper into the relationships between microstats and player impact. I have some projects in the works that will hopefully help bridge this gap, such as leveraging the play-by-play tracking data Corey provides to see its effects on expected goal generation, but that is for another time (hopefully). For now, one item that interests me is the consistency of these stats year over year for players that change teams. I alluded to the fact that these measures are dependent on a player’s role to some extent. A player like Connor McDavid would likely find himself carrying the puck a ton no matter the team he played for, but that is an extreme case. Most players would be heavily influenced by their team context and correspondingly would see shifts in their microstats output should they change teams. At least that is my hypothesis. Luckily this can be tested. I know some work has been done by Charlie O’Connor and Garik16 looking at the intra-season stability of entry and exit proclivity. I am not aware, however, of analysis that has been at players looking at inter-season consistency, let alone players that change teams. So that is what I am going to do here.\nBefore a start, I should note a few caveats. Corey does not track every minute of every shift that a player has at 5v5. He is one person, that would be impossible. This will be have to be a source of noise that we will accept when looking at the results. I am choosing to use a 100 minute cutoff for each seasonal pair (i.e. the player has at least 100 minutes tracked at 5v5 in each season). The other main caveat is that I am not taking into account the effects associated with aging. I would imagine, like any other statistics imaginable, that microstats are subject to aging curves. For those curious, I will include some aging curves at the end for the metrics I believe are most consistent across seasons. Finally, I am only using data from the 2017 through the 2020 season because Corey has each of the metrics summarized in a nicely organized spreadsheet. I wanted to get this analysis out there so I did not feel like spending the time it would require to go through the raw play-by-play logs creating the requisite summaries for the 2021 through 2023 seasons. If any of Corey’s patreons (or Corey himself) are aware of a spreadsheet with all of the statistics summarized for the other seasons, let me know and I can rerun my code including the more recent data.\nNow let us look at the results. Based on the criteria I set, there are 1632 eligible player-season pairs. Of those 1632 pairs, 1262 are of players who played on the same team year over year (and thus, 370 who changed clubs). 1062 players in the set are classified as forwards and the remaining 570 are defensemen. The following represents the year over year correlations between various statistics tracked by Corey, split up by whether the player in question changed teams year over year.\n\n\n\n\n\n\n\n\nFirst up are the forwards, with the chart on the left representing forwards who changed teams in between seasons and the chart on the right representing players who were on the same team season over season. Players who stayed put, unsurprisingly, have the higher year over year correlations across the board. These stats (and really all measures of player actions/performance) are some mixture of player skill and context/role. Naturally we want to tease out and isolate player skill, but these measures are undoubtedly influenced by a player’s teammates and the role which his coach asks him to take on.\nThe stats related to transition (exits/entries) are most stable year over year as are the more general measures for passing plays and shot attempts tracked. As the specificity of the offensive play type increases, the correlations decrease given we are dealing with a smaller sample relative to the total sample for shots and passes. The stats tracked covering actions in the defensive zone are basically noise for forwards; these actions are extremely infrequent.\n\n\n\n\n\n\n\n\nThese charts for defenders are oriented in the same way as their forward counterparts; players who changed teams on the left, the rest on the right. Similar to the forwards, the transition stats are stickier; more specifically, the transition stats related to exits. Defenders are much more involved in moving the puck out of their own zone relative to their responsibility for gaining entry into the offensive zone. This will naturally lead to a stronger year over year relationship given this is a responsibility that is more uniformly shared across team contexts whereas the role defenders play in their team’s offensive attack is more variable depending on team structure and coaching. Defenders show much smaller correlations for offensive play-types. As alluded to above, they are less involved offensively and thus we are looking at a smaller sample of plays across seasons. This is also most likely the result of defenders having less control over offensive play than forwards.\nFor the analysis on the whole, it is worth pointing out that we are looking at correlations (\\(R\\)), not coefficients of determination (\\(R^{2}\\)). The latter represents the proportion of one measure that can explain the other’s (in this case seasons N and N+1) variance. Thus, a correlation of approximately 0.707 (\\(\\frac{1}{\\sqrt{2}}\\)) would mean that the prior season’s values explain half the variance in the current season. Take a gander at the prior two charts. Very few measures for both player types reach that 50% threshold. Correlations of about 0.316 would indicate just a 10% \\(R^{2}\\). Arbitrary endpoints and whatnot, but no matter how we slice it there’s very little signal year over year signal, especially for players who change teams. We can conclude that much of these microstats are more descriptive than prescriptive and we should be paying most attention to entries/exits at a high level, shot and passing generation on the whole (i.e. without segmenting by type). That is not to tracking these play types and entry defense is not important in our understanding of the game; there is plenty of research that shows these are essential to goal generation and prevention. Moreover, for individual players, it seems that many of them do not represent repeatable skill across seasons and are highly dependent on team context and good old-fashioned variance.\nFinally, I will leave you with some aging curves for the more stable metrics. If there are any metrics not included here, feel free to contact me and I can produce those on your behalf."
  },
  {
    "objectID": "posts/predictive-woba/index.html",
    "href": "posts/predictive-woba/index.html",
    "title": "Developing a Predictive wOBA Measure",
    "section": "",
    "text": "Recently I read a blog post from Tom Tango at his personal site where he constructs a more predictive version of wOBA. I encourage you to give it a read, but I will quickly try to summarize his points and findings for those of you who may not have the time. He makes note of how xwOBA as found on Baseball Savant should be used: as an estimate for current wOBA based only on exit velocity and launch angle. He points out that this measure is often misinterpreted by public fans and analysts alike; it was/is not a prediction for future wOBA. Tango then goes on to construct a crude predictive wOBA (which is meant to be a player’s “true talent”) by bucketing batted balls by exit velocity and launch angle, taking the average wOBA of each bucket (which he refers to as the predictive wOBA for each bucket), and aggregates those values based on frequency for each player season. In the end, this measure proves to have a stronger correlation to the next season’s wOBA compared to both wOBA on its own and xwOBA. He concludes the post saying this method can be improved upon by incorporating the total batted balls in the sample, since one can surmise that the outcomes are more indicative of talent as the sample of batted balls increases.\nSo I attempted to do just that, with a slight twist by incorporating some more advanced modeling techniques. I started off with taking each player season since 2015 (the advent of publicly available batted ball information), bucketing the batted ball information as Tango did in his post, and adding some other measures. For those of you who did not read Tango’s original post, here is a key for how each batted ball is classified:\nBucket #\n      Exit Velocity Range (mph)\n      Launch Angle Range (°)\n    \n  \n  \n    1\n95 and Under\nOver 32\n    2\n95 and Under\nBetween 32 and 8\n    3\n95 and Under\nUnder 8\n    4\nBetween 100 and 95\nOver 32\n    5\nBetween 100 and 95\nBetween 32 and 8\n    6\nBetween 100 and 95\nUnder 8\n    7\nBetween 105 and 100\nOver 32\n    8\nBetween 105 and 100\nBetween 32 and 8\n    9\nBetween 105 and 100\nUnder 8\n    10\nOver 105\nOver 32\n    11\nOver 105\nBetween 32 and 8\n    12\nOver 105\nUnder 8\n  \n  \n    \n      Table theme via cbbdata\nAnd here is a sortable table with the data I am using for the model, which includes all players who recorded a batted ball. I will account for this information in the modeling process.\nWe have the data in hand, now we can model. The model will incorporate strikeout rates, walk rates, hit by pitch rates, the number of batted balls, the the frequency with which each player’s batted balls fall into the 12 aforementioned buckets. The target is going to be the following the player’s following season wOBA. I am going to use an XGBoost model for the regression and will tune the hyperparameters using a simulated annealing process from the handy finetune package. Let’s see how it looks:\nmultisession:\n- args: function (..., workers = availableCores(), lazy = FALSE, rscript_libs = .libPaths(), envir = parent.frame())\n- tweaked: FALSE\n- call: plan(multisession)\nLooks like diminishing returns as time went along, with a few outliers thrown in. Here are the five best models trained (based on RMSE):\nmtry\n      trees\n      tree_depth\n      learn_rate\n      rsme\n      n\n      std_err\n      iter\n    \n  \n  \n    1\n565\n8\n0.007817092\n0.08908047\n5\n0.002578514\n30\n    2\n742\n4\n0.006236565\n0.08912393\n5\n0.002867103\n16\n    4\n950\n4\n0.005835562\n0.08933424\n5\n0.002733826\n19\n    4\n742\n3\n0.010491683\n0.08937084\n5\n0.002771974\n17\n    5\n806\n5\n0.005438183\n0.08940414\n5\n0.002537927\n18\nWe have our list of models, so now we can select the best performing set of hyperparameters and get a final fit with feature importances.\nStrikeout rate is the most important feature in the model, followed by five features closely clustered together: walk rate and the frequency of buckets 3, 7, 8, and 11. Recall the key I provided above; bucket 3 corresponds to softly hit groundballs, bucket 7 solidly struck fly balls, bucket 8 solidly struck balls in the “sweet spot”, and bucket 11 the hardest hit batted balls in the “sweet spot” range. What can we draw from this? Plate skills (in the form of strikeout and walk rates) are extremely important in predicting next season’s wOBA for a player because, getting on base is good (shocker) and maximizing walks and minimizing strikeouts lead to getting on base. Second, those measures are incredibly stable year over year relative to other measures of player performance. As for the batted balls, it seems based on this analysis that avoiding poor contact on the ground, middling contact in the air that is likely to be caught be outfielders, and making hard contact at ideal launch angles is the best way to maximize production on contact. Nothing groundbreaking here, but it is nice to see that play out when analyzing the model.\nFinally we get to the models viability. The number to beat here is a \\(R^2\\) of 0.3704 with players who recorded 100 batted balls in both seasons (based on Tango’s blog post). How does this new model compare?\neval_tib &lt;- tib %&gt;% \n  bind_cols(predict(final_woba_mod, new_data = tib)) %&gt;% \n  filter(is.na(woba_next) == FALSE) %&gt;% # remove players who do not have a following season\n  rename(predicted_woba_next = .pred)\n\neval_tib &lt;- eval_tib %&gt;% mutate(bbe_n = as.double(bbe_n))\n\n# r-squared without filtering for guys with 100 BBEs\nprint(\n  paste(\"The coefficient of determination for the relationship between predicted and actual next season wOBA is\", \n  cor(eval_tib$woba_next, eval_tib$predicted_woba_next)^2 %&gt;% round(digits = 4), \n  sep = \" \"\n  )\n)\n\n[1] \"The coefficient of determination for the relationship between predicted and actual next season wOBA is 0.6091\"\n\n# filter for guys with 100 BBEs\nprint(\n  paste(\"The coefficient of determination for the relationship between predicted and actual next season wOBA for players with 100 BBEs in each season is\", \n  cor(eval_tib %&gt;% filter(bbe_n &gt;= 100, bbe_next &gt;= 100) %&gt;% .$woba_next, \n      eval_tib %&gt;% filter(bbe_n &gt;= 100, bbe_next &gt;= 100) %&gt;% .$predicted_woba_next)^2 %&gt;% \n    round(digits = 4), \n  sep = \" \"\n  )\n)\n\n[1] \"The coefficient of determination for the relationship between predicted and actual next season wOBA for players with 100 BBEs in each season is 0.6527\"\nNot bad (especially considering I did include any information about park factors or aging)! We cleared the bar that Tango set in his post before filtering for players with 100 batted balls, though obviously the degree of rigor with which I approached the problem was much different than Tom’s (who was concerned more presenting the concept of a predictive wOBA measure). He also did not incorporate walk or strikeout rates which feature prominently in this model. Nevertheless, I think this exercise here was a reasonable method of picking up where Tango left off by leveraging some more powerful modeling techniques. Just as important as being a good predictor of the future, analyzing the model yielded some important (though not necessarily novel) conclusions; mainly hitting the ball on the ground softly is bad, hitting fly balls that outfielders can easily catch is bad, and hitting the ball hard at optimal launch angles is the best way to ensure batted ball success.\nThere is one last note I want to make. I know there is some quibbling in the public space about not incorporating batted ball direction (in terms of spray angle) into a wOBA model. I would say two things can be true at the same time. The first is that directly incorporating the spray angle of a batted ball might make a model’s estimation of that singular batted ball more accurate, but I have found that when incorporating spray angle and aggregating the model outputs at the player level does not increase the predictiveness of the model, similar to the folks at MLBAM. That can be something I post about in the future (feel free to bother me on Twitter to get around to writing up the post). Whether this is the result of most players not being able to “cheat” their exit velocities consistently year over year by pulling the ball down the line, exit velocity and launch angle being so much more important than spray angle over time, or having a model with less parameters is going to introduce more sources of variance, I find it difficult to conclude spray angle must be included to make a batted ball model viable over a sufficient sample. At some point I plan at looking a pull rates, their repeatability, and how much control batters have over them (pitch location has some bearing on whether a ball is pulled as does how far in front of the plate the batter makes contact. Unfortunately the latter data is not available publicly).\nNow the second thing: spray angle does have some effect on exit velocity. Pulled balls result in higher exit velocities for a given player, so those who can consistently put the ball in the air will maximize whatever power they have in the tank (see Marcus Semien or Isaac Paredes). I know Robert Orr has done excellent work adjusting exit velocities for spray angle, as did Connor Kurcon before he was hired by the Astros. Alex Chamberlain also has written a great primer on the relationship between exit velocity and spray angle at FanGraphs. I think the way to bridge the gap between those concerned with ignoring spray angle and the fact that player-level predicted wOBAs seem to not be aided by the inclusion of spray angle is to incorporate exit velocities adjusted for spray angle and undergo a similar process as I have done above (add that to the list of things I want to work on). My hypothesis is that this will yield even more predictive results for player hitting skill, but I cannot know for sure until I do the work myself or someone decides to take it up themselves."
  },
  {
    "objectID": "posts/predictive-woba/index.html#appendix",
    "href": "posts/predictive-woba/index.html#appendix",
    "title": "Developing a Predictive wOBA Measure",
    "section": "Appendix",
    "text": "Appendix\nAt the end I wanted to include a table for those curious that includes wOBA, next season wOBA, and the predicted next season wOBA. I filtered for players with 50 batted ball events in each season and made it sortable and searchable."
  },
  {
    "objectID": "batter_table.html",
    "href": "batter_table.html",
    "title": "Batter Table",
    "section": "",
    "text": "This table contains batter rate stats for all pitches faced and is segmented by pitch type. To only look at all pitches faced, type “All” into the dialog box in the type column. All columns are sortable."
  },
  {
    "objectID": "posts/stephenson-cutter/index.html",
    "href": "posts/stephenson-cutter/index.html",
    "title": "Robert Stephenson’s Cutter",
    "section": "",
    "text": "A recent tweet from Lance Brozdowski where he wonders whether the change Robert Stephenson made going from Pittsburgh to Tampa was the result of altering the velocity of his slider to turn it into a cutter instead of changing the grip is a poignant one. If you cannot read the tweet or are resistant to clicking on the link, I will provide the two pictures below.\n\n\n\nPIT Grip\n\n\n\n\n\nTB Grip\n\n\nThis was a great pull and an interesting hypothesis. To take it once step further, I wanted to write up a quick post looking at the pitch characteristics and see if I can support Brozdowski’s assertion. Stepheson did not throw a cutter until he joined the Rays; with the Pirates he was basically a fastball-slider guy.\n\n\n\n\n\n\n  \n    \n    \n      Season\n      Team\n      CU\n      FF\n      SL\n      FS\n      FC\n    \n  \n  \n    2022\n\n2.4\n28.2\n69.4\n0.0\n0.0\n    2023\n\n0.8\n31.2\n62.9\n5.1\n0.0\n    2023\n\n0.0\n20.2\n6.7\n13.1\n60.1\n  \n  \n  \n    \n       % of total pitches thrown\n    \n  \n\n\n\n\nThe majority of his offerings with the Rays consisted of cutters, with a few more splitters thrown in. The slider was almost non-existent, especially relative to its usage in Pittsburgh. We know that the line between sliders and cutters is murky at a certain point in space, so was there really a substantive difference? I would definitively argue there was. The slider in Tampa came in at 85.3 MPH and in Pittsburgh 84.6, effectively identical. The cutter he threw at 88.7 mph on average. The movement patterns were also noticeably different, which Lance talked about in one of his YouTube videos.\n\n\n\n\n\nThe pitches colored yellow represent those from his time in Pittsburgh and correspondingly those in teal are from his time in Tampa. The cutters with the Rays are clustered in the top left, designating pitches with ride (i.e. backspin) and arm-side movement. There is some overlap with the pitches designated as sliders; the cutter can drift towards the glove-side with no magnus movement in the z-direction (almost a pure gyroball). The lack of consistency in the movement pattern might be construed as a negative but the pitch garnered a 59.9% whiff rate. For a pitch to be thrown that often and generate swings and misses at that rate, you can see why Stephenson struck out so many batters in Tampa.\nSo the new pitch is good. Great. But back to the original question and point of the post: What is he doing differently if the grips between the two pitches look the same? There has to be some difference, given the distinction in movement profiles. We know he’s throwing the pitch with more velocity. I explained that above. But there is something more going on here.\n\n\n\n\n\nAt least based on the 2D spin axes captured by the HawkEye cameras, the cutter and slider have functionally the same spin axis, but the ball is spinning in opposite directions.\n\n\n\n\n\nNow here is what the spin axes look like based on the movement of the pitches (credit to Dr. Alan Nathan for his work enabling me to perform these calculations). This mirroring phenomenon is still present in the inferred axes from the pitch movement; both pitches seem to leverage some modicum of movement from seam-effects to the tune of about 30 degrees of axis differential between the actual and inferred 2D spin axes. Not only is this the same for the cutter and slider, but the absolute deviations are also in the same direction (clockwise from this perspective). One last aspect of the pitches I wanted to check was the estimated amount of gyroscopic spin (i.e. bullet, or football-type spin) using “the angle of the spin with respect to the x − z plane” (again, based on Dr. Nathan’s work). 90 degrees represents pure gyroscopic spin, 0 represents pure transverse spin.\n\n\n\n\n\nThese pitches similarly have the vast majority of their spin in the form of gyroscopic spin, which is not surprising with their movement profiles clustering around the (0, 0) point in the short-form movement plot above.\nI said at the top this was going to be a short post, so I will leave you with this. Stephenson’s slider and cutter are very similar. They are thrown with similar amounts of gyro spin, the movement profiles are close to each other, they probably have similar movement bumps from seam-effects. The thing is, while they spin around the same axis, they do so in the complete opposite direction! For all the similarities, they are actually mirrors of each other. How did the Rays coax this out of him and help develop one of the the best pitches in baseball that yielded Stephenson an eight figure, multi-year guaranteed contract? Was it simply telling him to throw the ball with more velocity and this phenomenon was a natural byproduct? Or is there more at play here? Perhaps changing the distribution of pressure he’s putting on the ball with his index and middle fingers, where the cutter gets more backspin by having the index finger apply more pressure on the ball relative to the slider? That is a lot of questions to conclude a piece, but that is all we can really do. Without Stephenson or the Rays going on the record documenting what happened after Stephenson was traded to Tampa, it is impossible to know the tweak. Nevertheless, an interesting development and a great catch by Lance Brozdowski."
  }
]