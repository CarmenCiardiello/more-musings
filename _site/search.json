[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "My name is Carmen Ciardiello. I am an engineer who has worked in an MLB front office as a Research & Development Analyst and have written at FanGraphs as a part-time contributor. You can easily look back at my FanGraphs archive by searching for name followed by FanGraphs. Some of my early research can be found at sabermetricmusings.blogspot.com.\nFeel free to contact me on Twitter or email my at cciardiello1@gmail.com with any questions for concerns regarding my work on this site or anything else that may cross your mind. I am always happy to discuss baseball, other sports, programming, and all combinations thereof."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sporting Musings",
    "section": "",
    "text": "Hockey Microstats Repeatability\n\n\n\n\n\n\n\nhockey\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2024\n\n\nCarmen Ciardiello\n\n\n\n\n\n\n  \n\n\n\n\nHitter Velocity Splits\n\n\n\n\n\n\n\nbaseball\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2024\n\n\nCarmen Ciardiello\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/velocity-splits/index.html",
    "href": "posts/velocity-splits/index.html",
    "title": "Hitter Velocity Splits",
    "section": "",
    "text": "One avenue of analysis I see most around the postseason when individual batter-pitcher matchups or team matchups are more heavily scrutinized is bucketing offensive performance by velocity faced, specifically against fastballs. An analyst might posit “This bullpen has thrown X percent of its fastballs over 95 mph and this team has produced a Y wOBA on such pitches.” Or something along the lines of “John Doe is going to have a tough go of it against this teams cadre of high octane arms; he has posted an X wOBA on fastballs over 95 mph, versus Y on fastballs below that threshold.” Similar points might be made in an analysis of a player in the midst of a slump during the championship season (instances that come to mind are various pieces related to Jose Abreu from 2023, for example). In all of these cases, the performance against what many would call “premium velocity” or “95+”, which at this point in time I would argue does not constitute premium velocity (reminds me of this Effectively Wild episode), is certainly descriptive. We take what happened in the past, create a cutoff (albeit an arbitrary one), and calculate the respective wOBAs.\nThat is all well and good, a description of that happened in the past. But I have few points of contention with type of analysis, either at the player or team level. The first, which I have already alluded to, is the arbitrary point at which most decide to bucket the data. This is almost always 95 mph. I am not aware of why this became the accepted line of demarcation; I would guess it just looks like a nice round number. Or maybe it is related to MLB’s definition of a hard hit ball, also 95 mph. Nevertheless, I can appreciate the desire to bucket information for ease of analysis or understanding. Modelling this in a continuous manner and presenting the results is often a more cumbersome endeavor and may lose some of the readers. A trivial comparison of performance on either side of a cutoff is more digestible. I suggest in the future, maybe we use cutoff based on velocity percentile? League-wide velocity is not a static figure, thus the significance of the 95 mph figure is different in say 2023 versus 2015.\nThe arbitrary buckets are one issue, but like I said I can understand the impetus for wanting to structure analysis in this way. My main issue the the usefulness of this information altogether, in that I am very skeptical that this sort of analysis yields valuable insights into performance in the past or future. The usage of wOBA as the measure of choice belies a player/team’s performance against higher velocity pitches because it only considers pitches that mark the end of a plate appearance. All of the fastballs that a player swings through with either zero or one strike are not considered at all. Furthermore, using wOBA muddies the picture by not distinguishing whether a player/team struggles with making contact or producing damage on contact. If you want to demonstrate an effectiveness (or lack thereof) against velocity, these two skills need to be separated out. The easiest method would be to consider whiff or swinging strike rate and wOBACON (or some measure concerned solely with contact quality). This criticism does not apply to all analyses of this type, but it is something that I see quite often and think needs to be adjudicated. I understand this distinction can be a bit tricky. It requires a few different Savant searches and some spreadsheet jockeying. But failing to make this distinction prohibits any conclusions one draws from being revealing.\nNow, let us move on to the functionality of bucketing performance by velocity faced, even after making the distinction between contact and contact quality. Looking at contact (in the form of swinging strike rate) or contact quality (in the form of wOBACON) there has been been a standard bell curve for deviations in performance against higher and lower velocity, looking solely at players who accumulated 100 plate appearances in a given season since 2015.\n\n\n\n\n\nThere are a few conclusions we can draw from these figures. First, these look like standard Gaussian distributions. The swinging strike rate figure is centered close to around 0.05 (i.e. the median player has a swinging strike rate about five percentage points higher against 95+ mph fastballs). The wOBACON plot is similarly shaped, but around 0 (i.e. the point where there is no difference between a player’s wOBACON when you bucket balls in play by velocity faced). The shapes of both figures indicates one of two things: either the talent in facing higher end velocity (relative to lower velocity) is normally distributed in MLB or the differences in the two figures are random around the league-wide mean. The fact that the wOBACON figure is centered around zero lends credence to the latter; intuitively players should not be expected to produce better against higher velocity. Therefore, using a threshold of 100 PAs, looking at a season’s worth of PAs is not sufficient in judging a player’s ability to face high end velocity. For swinging strikes, there is a bit more to consider given the center of the distribution is located at a value that makes sense; we expect (and know) that higher velocity pitches (all else being equal) result in more whiffs. But still, within a season, any difference that deviates from that medium is mostly noise because year over year, there is little to no consistency in those deviations\n\n\n\n\n\nThis whole post is a long-winded plea to caution analysts looking to find signal in any velocity-based splits when it comes to batting performance (this can undoubtedly be said for any analysis leveraging splits). We know facing higher end velocity is going to result in lower offensive performance on the whole(evident in the depressed offensive environment of the postseason). But there is little to no evidence that players are particularly adept or poor at facing high end velocity relative to lower velocity at the major league level. There might be something to explore when looking at minor league players, where the distribution of talent is much wider. Without extensive minor league pitch-tracking publicly available, however, this is not possible to verify at this point in time."
  },
  {
    "objectID": "posts/microstats-repeatability/index.html",
    "href": "posts/microstats-repeatability/index.html",
    "title": "Hockey Microstats Repeatability",
    "section": "",
    "text": "The proliferation of “microstats” in the public space has been a boon in our understanding of hockey players. These stats include entries/exits (the concept and tracking of which were pioneered by Eric Tulsky), entry denials, and various types of passing plays (which to my knowledge were first studied in depth by Ryan Stimson). Corey Sznajder has been tracking this phylum of statistics and releasing them to the patrons of his All Three Zones project for public consumption and analysis. Corey has been an invaluable in increasing our understanding of the various skills players display while on the ice and his data is readily available for public-facing analysts to dig into.\nThese statistics can tell us why or how a player comes about his production. But they do not approximate player value on their own. Jack Fraser, in a newsletter post from several years ago, cautions people in using microstats to assess player ability. He stresses that these measures events, what actually is happening on the ice. We know that at the team level certain passing plays and transition into and out of the neutral zone are indicators of successfully driving goal differential and generation from the work of Tulsky and Stimson. At the player level this is not necessarily true. There are plenty of players who are not tasked with transporting the puck up the ice that provide significant value to their clubs. Look no further than Jason Robertson. A player not necessarily the most fleet of foot, Robertson defers these responsibilities to his more dynamic linemates (most notably Roope Hintz) and does his part by making himself available to receive passes in the offensive zone, where he can then put shots on net or parley the reception into another pass in the offensive zone to scramble the opposition. I think any fan or analyst following the NHL the past few years would agree that Robertson is one of the better wingers in the league, but he certainly does not stand out when looking at Corey’s tracking of transition plays. At the other end of the spectrum, successfully generating exits and entries is not a one way ticket for effectiveness. Look no further than Max Domi.\nAll of this is to say is that these tracked statistics are not the be all and end all in evaluating hockey players. There are skills that are clearly not captured that help players drive goal differentials for their team. I will say that if a player stands out in all or most of the tracking statistics, there is a decent chance that player is doing something right; but not definitively.\nThat is my preamble and at some point I would like to look deeper into the relationships between microstats and player impact. I have some projects in the works that will hopefully help bridge this gap, such as leveraging the play-by-play tracking data Corey provides to see its effects on expected goal generation, but that is for another time (hopefully). For now, one item that interests me is the consistency of these stats year over year for players that change teams. I alluded to the fact that these measures are dependent on a player’s role to some extent. A player like Connor McDavid would likely find himself carrying the puck a ton no matter the team he played for, but that is an extreme case. Most players would be heavily influenced by their team context and correspondingly would see shifts in their microstats output should they change teams. At least that is my hypothesis. Luckily this can be tested. I know some work has been done by Charlie O’Connor and Garik16 looking at the intra-season stability of entry and exit proclivity. I am not aware, however, of analysis that has been at players looking at inter-season consistency, let alone players that change teams. So that is what I am going to do here.\nBefore a start, I should note a few caveats. Corey does not track every minute of every shift that a player has at 5v5. He is one person, that would be impossible. This will be have to be a source of noise that we will accept when looking at the results. I am choosing to use a 100 minute cutoff for each seasonal pair (i.e. the player has at least 100 minutes tracked at 5v5 in each season). The other main caveat is that I am not taking into account the effects associated with aging. I would imagine, like any other statistics imaginable, that microstats are subject to aging curves. For those curious, I will include some aging curves at the end for the metrics I believe are most consistent across seasons. Finally, I am only using data from the 2017 through the 2020 season because Corey has each of the metrics summarized in a nicely organized spreadsheet. I wanted to get this analysis out there so I did not feel like spending the time it would require to go through the raw play-by-play logs creating the requisite summaries for the 2021 through 2023 seasons. If any of Corey’s patreons (or Corey himself) are aware of a spreadsheet with all of the statistics summarized for the other seasons, let me know and I can rerun my code including the more recent data.\nNow let us look at the results. Based on the criteria I set, there are 1632 eligible player-season pairs. Of those 1632 pairs, 1262 are of players who played on the same team year over year (and thus, 370 who changed clubs). 1062 players in the set are classified as forwards and the remaining 570 are defensemen. The following represents the year over year correlations between various statistics tracked by Corey, split up by whether the player in question changed teams year over year.\n\n\n\n\n\n\n\n\nFirst up are the forwards, with the chart on the left representing forwards who changed teams in between seasons and the chart on the right representing players who were on the same team season over season. Players who stayed put, unsurprisingly, have the higher year over year correlations across the board. These stats (and really all measures of player actions/performance) are some mixture of player skill and context/role. Naturally we want to tease out and isolate player skill, but these measures are undoubtedly influenced by a player’s teammates and the role which his coach asks him to take on.\nThe stats related to transition (exits/entries) are most stable year over year as are the more general measures for passing plays and shot attempts tracked. As the specificity of the offensive play type increases, the correlations decrease given we are dealing with a smaller sample relative to the total sample for shots and passes. The stats tracked covering actions in the defensive zone are basically noise for forwards; these actions are extremely infrequent.\n\n\n\n\n\n\n\n\nThese charts for defenders are oriented in the same way as their forward counterparts; players who changed teams on the left, the rest on the right. Similar to the forwards, the transition stats are stickier; more specifically, the transition stats related to exits. Defenders are much more involved in moving the puck out of their own zone relative to their responsibility for gaining entry into the offensive zone. This will naturally lead to a stronger year over year relationship given this is a responsibility that is more uniformly shared across team contexts whereas the role defenders play in their team’s offensive attack is more variable depending on team structure and coaching. Defenders show much smaller correlations for offensive play-types. As alluded to above, they are less involved offensively and thus we are looking at a smaller sample of plays across seasons. This is also most likely the result of defenders having less control over offensive play than forwards.\nFor the analysis on the whole, it is worth pointing out that we are looking at correlations (\\(R\\)), not coefficients of determination (\\(R^{2}\\)). The latter represents the proportion of one measure that can explain the other’s (in this case seasons N and N+1) variance. Thus, a correlation of approximately 0.707 (\\(\\frac{1}{\\sqrt{2}}\\)) would mean that the prior season’s values explain half the variance in the current season. Take a gander at the prior two charts. Very few measures for both player types reach that 50% threshold. Correlations of about 0.316 would indicate just a 10% \\(R^{2}\\). Arbitrary endpoints and whatnot, but no matter how we slice it there’s very little signal year over year signal, especially for players who change teams. We can conclude that much of these microstats are more descriptive than prescriptive and we should be paying most attention to entries/exits at a high level, shot and passing generation on the whole (i.e. without segmenting by type). That is not to tracking these play types and entry defense is not important in our understanding of the game; there is plenty of research that shows these are essential to goal generation and prevention. Moreover, for individual players, it seems that many of them do not represent repeatable skill across seasons and are highly dependent on team context and good old-fashioned variance.\nFinally, I will leave you with some aging curves for the more stable metrics. If there are any metrics not included here, feel free to contact me and I can product those on your behalf."
  },
  {
    "objectID": "posts/microstats-repeatability/index.html#overview",
    "href": "posts/microstats-repeatability/index.html#overview",
    "title": "Hockey Microstats Repeatability",
    "section": "",
    "text": "The proliferation of “microstats” in the public space has been a boon in our understanding of hockey players. These stats include entries/exits (the concept and tracking of which were pioneered by Eric Tulsky), entry denials, and various types of passing plays (which to my knowledge were first studied in depth by Ryan Stimson). Corey Sznajder has been tracking this phylum of statistics and releasing them to the patrons of his All Three Zones project for public consumption and analysis. Corey has been an invaluable in increasing our understanding of the various skills players display while on the ice and his data is readily available for public-facing analysts to dig into.\nThese statistics can tell us why or how a player comes about his production. But they do not approximate player value on their own. Jack Fraser, in a newsletter post from several years ago, cautions people in using microstats to assess player ability. He stresses that these measures events, what actually is happening on the ice. We know that at the team level certain passing plays and transition into and out of the neutral zone are indicators of successfully driving goal differential and generation from the work of Tulsky and Stimson. At the player level this is not necessarily true. There are plenty of players who are not tasked with transporting the puck up the ice that provide significant value to their clubs. Look no further than Jason Robertson. A player not necessarily the most fleet of foot, Robertson defers these responsibilities to his more dynamic linemates (most notably Roope Hintz) and does his part by making himself available to receive passes in the offensive zone, where he can then put shots on net or parley the reception into another pass in the offensive zone to scramble the opposition. I think any fan or analyst following the NHL the past few years would agree that Robertson is one of the better wingers in the league, but he certainly does not stand out when looking at Corey’s tracking of transition plays. At the other end of the spectrum, successfully generating exits and entries is not a one way ticket for effectiveness. Look no further than Max Domi.\nAll of this is to say is that these tracked statistics are not the be all and end all in evaluating hockey players. There are skills that are clearly not captured that help players drive goal differentials for their team. I will say that if a player stands out in all or most of the tracking statistics, there is a decent chance that player is doing something right; but not definitively.\nThat is my preamble and at some point I would like to look deeper into the relationships between microstats and player impact. I have some projects in the works that will hopefully help bridge this gap, such as leveraging the play-by-play tracking data Corey provides to see its effects on expected goal generation, but that is for another time (hopefully). For now, one item that interests me is the consistency of these stats year over year for players that change teams. I alluded to the fact that these measures are dependent on a player’s role to some extent. A player like Connor McDavid would likely find himself carrying the puck a ton no matter the team he played for, but that is an extreme case. Most players would be heavily influenced by their team context and correspondingly would see shifts in their microstats output should they change teams. At least that is my hypothesis. Luckily this can be tested. I know some work has been done by Charlie O’Connor and Garik16 looking at the intra-season stability of entry and exit proclivity. I am not aware, however, of analysis that has been at players looking at inter-season consistency, let alone players that change teams. So that is what I am going to do here.\nBefore a start, I should note a few caveats. Corey does not track every minute of every shift that a player has at 5v5. He is one person, that would be impossible. This will be have to be a source of noise that we will accept when looking at the results. I am choosing to use a 100 minute cutoff for each seasonal pair (i.e. the player has at least 100 minutes tracked at 5v5 in each season). The other main caveat is that I am not taking into account the effects associated with aging. I would imagine, like any other statistics imaginable, that microstats are subject to aging curves. For those curious, I will include some aging curves at the end for the metrics I believe are most consistent across seasons. Finally, I am only using data from the 2017 through the 2020 season because Corey has each of the metrics summarized in a nicely organized spreadsheet. I wanted to get this analysis out there so I did not feel like spending the time it would require to go through the raw play-by-play logs creating the requisite summaries for the 2021 through 2023 seasons. If any of Corey’s patreons (or Corey himself) are aware of a spreadsheet with all of the statistics summarized for the other seasons, let me know and I can rerun my code including the more recent data.\nNow let us look at the results. Based on the criteria I set, there are 1632 eligible player-season pairs. Of those 1632 pairs, 1262 are of players who played on the same team year over year (and thus, 370 who changed clubs). 1062 players in the set are classified as forwards and the remaining 570 are defensemen. The following represents the year over year correlations between various statistics tracked by Corey, split up by whether the player in question changed teams year over year.\n\n\n\n\n\n\n\n\nFirst up are the forwards, with the chart on the left representing forwards who changed teams in between seasons and the chart on the right representing players who were on the same team season over season. Players who stayed put, unsurprisingly, have the higher year over year correlations across the board. These stats (and really all measures of player actions/performance) are some mixture of player skill and context/role. Naturally we want to tease out and isolate player skill, but these measures are undoubtedly influenced by a player’s teammates and the role which his coach asks him to take on.\nThe stats related to transition (exits/entries) are most stable year over year as are the more general measures for passing plays and shot attempts tracked. As the specificity of the offensive play type increases, the correlations decrease given we are dealing with a smaller sample relative to the total sample for shots and passes. The stats tracked covering actions in the defensive zone are basically noise for forwards; these actions are extremely infrequent.\n\n\n\n\n\n\n\n\nThese charts for defenders are oriented in the same way as their forward counterparts; players who changed teams on the left, the rest on the right. Similar to the forwards, the transition stats are stickier; more specifically, the transition stats related to exits. Defenders are much more involved in moving the puck out of their own zone relative to their responsibility for gaining entry into the offensive zone. This will naturally lead to a stronger year over year relationship given this is a responsibility that is more uniformly shared across team contexts whereas the role defenders play in their team’s offensive attack is more variable depending on team structure and coaching. Defenders show much smaller correlations for offensive play-types. As alluded to above, they are less involved offensively and thus we are looking at a smaller sample of plays across seasons. This is also most likely the result of defenders having less control over offensive play than forwards.\nFor the analysis on the whole, it is worth pointing out that we are looking at correlations (\\(R\\)), not coefficients of determination (\\(R^{2}\\)). The latter represents the proportion of one measure that can explain the other’s (in this case seasons N and N+1) variance. Thus, a correlation of approximately 0.707 (\\(\\frac{1}{\\sqrt{2}}\\)) would mean that the prior season’s values explain half the variance in the current season. Take a gander at the prior two charts. Very few measures for both player types reach that 50% threshold. Correlations of about 0.316 would indicate just a 10% \\(R^{2}\\). Arbitrary endpoints and whatnot, but no matter how we slice it there’s very little signal year over year signal, especially for players who change teams. We can conclude that much of these microstats are more descriptive than prescriptive and we should be paying most attention to entries/exits at a high level, shot and passing generation on the whole (i.e. without segmenting by type). That is not to tracking these play types and entry defense is not important in our understanding of the game; there is plenty of research that shows these are essential to goal generation and prevention. Moreover, for individual players, it seems that many of them do not represent repeatable skill across seasons and are highly dependent on team context and good old-fashioned variance.\nFinally, I will leave you with some aging curves for the more stable metrics. If there are any metrics not included here, feel free to contact me and I can product those on your behalf."
  }
]